{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a54f1d43",
   "metadata": {},
   "source": [
    "# Laboratory 4: Convolutional Neural Networks\n",
    "\n",
    "In this laboratory session we will train some CNNs to recognize color images in the [CIFAR-10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbcd5fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 1: Initial Setup and Data Exploration\n",
    "\n",
    "We begin with some standard imports, as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa0017bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "# Standard Pytorch imports (note the aliases).\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607cc4cb",
   "metadata": {},
   "source": [
    "### Exercise 1.1: Dataset and Dataloader Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5488263d",
   "metadata": {},
   "source": [
    "The `torchvision` library provides a class (with the same interface as MNIST) for the CIFAR-10 dataset. As with MNIST, it will automatically download and prepare the dataset for use. Use the CIFAR10 class to load the training (use a subset, say of 5000 images), validation (use an **independent** subset of 2000 images from the training set), and test splits.\n",
    "\n",
    "**Note**: Don't forget to *transform* the images in the datasets to convert them to tensors and standardize them!\n",
    "\n",
    "**Hint**: Feel free to copy-and-paste liberally from the notebook I published for the capsule lecture. **BUT**, make sure you know what you are doing, and be aware that *some* of the code will have to be adapted for use with the CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e468226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Validation and train set size.\n",
    "train_size = 5000\n",
    "val_size = 2000\n",
    "\n",
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93be2f0e",
   "metadata": {},
   "source": [
    "### Exercise 1.2: Dataloaders\n",
    "Set up dataloaders for **all** of the datasets -- even though the validation set is small! Test out the datasets defined above and the dataloaders to make sure you understand the dataset format. Visualize some of the images to get a feel for the type of images and classes in CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84efdf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup dataloaders for all three datasets. Use the largest batch size possible.\n",
    "batch_size = 256\n",
    "\n",
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a759bbd",
   "metadata": {},
   "source": [
    "## Part 2: Establishing a stable baseline\n",
    "\n",
    "In this part of the laboratory we will establish a simple baseline as a starting point.\n",
    "\n",
    "### Exercise 2.1: An MLP Baseline\n",
    "\n",
    "Define a simple Multilayer Perceptron to classify the CIFAR-10 images. Define it as a class inheriting from torch.nn.Module. Don't make it too complex or too deep. We're just looking for a starting point. A *baseline*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b67295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98427e54",
   "metadata": {},
   "source": [
    "### Exercise 2.2: Train and Evaluate your MLP Baseline\n",
    "\n",
    "Train the model for a few (say, 20) epochs. Again, feel free to use my training code from the Capsule Lecture (or roll your own, mine is very basic). Make sure you plot training curves for both training and validation sets, and report finalaccuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cc96ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14689935",
   "metadata": {},
   "source": [
    "## Part 3: A CNN for CIFAR-10 Classification\n",
    "\n",
    "OK, we have a (simple) MLP baseline for comparison. Let's implement a simple CNN to classify CIFAR-10 images and see if we can beat the MLP.\n",
    "\n",
    "### Exercise 3.1: Defining the CNN\n",
    "\n",
    "Define a simple CNN model with a few convolutional and maxpooling layers -- not too many, since CIFAR-10 images are only 32x32 pixels! Use two fully-connected layers after the last convolution and before the logit outputs. Test out the model by passing a *single* image through it to make sure it's working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5247ae16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e4c413-6428-49db-a877-32f7ee2c67c1",
   "metadata": {},
   "source": [
    "### Exercise 3.2: Training and Evaluating your CNN\n",
    "\n",
    "Train the CNN using similar hyperparameters to what you used for the MLP above (epochs, learning rate). Evaluate the model in the same way as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98f9664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5315f3-4a62-48ee-b647-8f3f6ed55ab2",
   "metadata": {},
   "source": [
    "### Exercise 3.3: Adding data augmentation\n",
    "\n",
    "See if you can improve the results of your CNN on CIFAR-10 by adding **data augmentation** to your training pipeline. To do this you will have to rethink your `Dataset` definition in order to incorporate random geometric transformations to images requested by your *training* `DataLoader`.\n",
    "\n",
    "**Hint**: A good starting place for this is the **Torchvision** documentation for the `transforms` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "598232cb-372d-423f-8a17-60c5e424af88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75dd514-4970-473c-84c5-4632b32fd599",
   "metadata": {},
   "source": [
    "## Part 4: Going Forward\n",
    "\n",
    "In practice we usually don't train deep models from *scratch*. Especially if we don't have a lot of annotated data we almost always use a **pre-trained** model either as a **feature extractor** or to **fine-tune** on our problem. The Torchvision library supports access to a [huge variety or pre-trained models](https://pytorch.org/vision/stable/models/resnet.html) that you can use for *exactly* this purpose. Always keep this in mind if you have an image recognition problem -- you can use a pre-trained model as a **feature extractor** and then train a *simple* MLP to solve your classification problem. This works *very* well in practice.\n",
    "\n",
    "### Exercise 4.1: Adapt a pre-trained model\n",
    "\n",
    "Adapt a ResNet (e.g. ResNet-18) pre-trained on ImageNet to classify images from CIFAR-10. Carefully consider what changes you might have to make in your pipeline to make CIFAR-10 images compatible with a network as deep as ResNet-18. There are several strategies you could take to perform this adaptation:\n",
    "+ You could use the pre-trained ResNet as a **feature extractor** by computing the final hidden layer activations (i.e. the layer just before the classifier) on the entire training set. Then, you could train an MLP to classify the ten CIFAR-10 classes.\n",
    "+ As an alternative, you could **fine-tune** the ResNet on the new dataset. To do this you will need to substitute the final classification layer with a new, linear layer for the ten-class classification problem of CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44a5b00e-6d9f-4bfc-888a-6238c9c3ddd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision.transforms import Compose, ToTensor, Resize   # <-- There is a hint in this import.\n",
    "from torchvision.datasets import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd2fcf26-ca5d-481b-8be4-e596e629b86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

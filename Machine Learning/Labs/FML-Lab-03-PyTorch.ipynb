{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bdf7099-a6d0-4b18-9216-f8e6701842f6",
   "metadata": {},
   "source": [
    "# CODE OF CONDUCT V1.0\n",
    "\n",
    "This Code of Conduct outlines principles for the ethical and transparent use of Large Language Models (LLMs) and existing and internet resources, ensuring integrity and accountability in your laboratory submissions. This first version of the FML Laboratory Code of Conduct was developed in a brainstorming session with **ChatGPT Version 2**, modifying its proposal to the specifics of the FML Laboratories and concentrating on the transparent collaboration with classmates and transparent use of LLMs.\n",
    "\n",
    "#### **1. Transparency in LLM Use**\n",
    "- **Clear Disclosure:** Explicitly state when Large Language Models (LLMs) are used in any part of the process, including data analysis, code generation, or writing.\n",
    "- **Model Limitations:** Acknowledge the inherent limitations of LLMs, such as potential biases, and make clear where human intervention was applied to verify results or to modify/augment produced code.\n",
    "\n",
    "#### **2. Proper Attribution and Documentation**\n",
    "- **Attribution:** Provide appropriate citations and credits for all external resources, including code, data, and models.\n",
    "- **Clear Documentation:** Maintain detailed records of tools, methods, and models used, ensuring transparency and reproducibility in your submitted laboratory solutions.\n",
    "\n",
    "#### **3. Collaboration and Individual Work**\n",
    "- **Sharing Solutions:** While collaboration and discussing ideas with classmates are encouraged, solutions to assignments or projects should be your own. Do not copy or submit work created by others, including code or models, as your own.\n",
    "- **Submission Integrity:** All submitted work must reflect your own understanding and effort. If external tools, LLMs, online resources, or code from your classmates were used, they must be properly documented, but the final submission must be an individual effort.\n",
    "\n",
    "#### **4. Accountability**\n",
    "Non-compliance with these guidelines will be subject to review by the course exam commission, with possible disciplinary actions.\n",
    "\n",
    "---\n",
    "\n",
    "# Laboratory 3: Getting started with Pytorch\n",
    "\n",
    "In this laboratory we will begin working with Pytorch to implement and train complex, nonlinear models for supervised learning problems. You will notice many similarities between Numpy and Pytorch -- this is deliberate, but it can cause some confusion and for many things we will have to convert back and forth between Numpy arrays and Pytorch tensors.\n",
    "\n",
    "**Super Important**: You will notice that this laboratory is much less *guided* and it doesn't *prompt* you for \"Your analysis here\". You are expected to be creative and analyze when and how it is appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3117a44-c264-469e-91b6-2cc445413903",
   "metadata": {},
   "source": [
    "## Part 0: First steps\n",
    "\n",
    "**Important**: You **must** install Pytorch in your Anaconda environment for this laboratory. The easiest way to do this is to just install the CPU version of Pytorch like this:\n",
    "\n",
    "```\n",
    "conda activate FML\n",
    "conda install -c pytorch pytorch torchvision\n",
    "```\n",
    "\n",
    "**Note**: If you have an Nvidia GPU on your computer you can also install the GPU-enabled version of Pytorch which will **greatly** improve performance for more complex models and larger datasets. However, it can be very hard to get all of the versions of the required libraries to match correctly... During the laboratory we can look at it together if you are interested.\n",
    "\n",
    "After installing Pytorch, use the next cell to verify that the installation is working. If it prints a 3x3 sensor, we're good to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfcdca90-bf99-4c35-b7e3-961f6ba45cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0173,  0.6601,  0.4005],\n",
      "        [-0.7348,  0.7139,  1.0501],\n",
      "        [ 0.1340, -0.9955, -0.2573]])\n"
     ]
    }
   ],
   "source": [
    "# We're still going to need numpy and matplotlib.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Verify that pytorch is working.\n",
    "import torch\n",
    "\n",
    "# If this works, things should be OK.\n",
    "print(torch.randn((3, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6f7466-0f8f-406e-a4e7-24e8a8135f8a",
   "metadata": {},
   "source": [
    "## Part 1: Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebc2242-e79a-4e67-af09-8318126dde0e",
   "metadata": {},
   "source": [
    "We will work with the venerable MNIST dataset of handwritten digits in this laboratory. The `torchvision` library provides classes for a bunch of standard datasets, including MNIST. These classes automatically download and prepare the dataset for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af0151f-9897-4fa0-8832-4603979427df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load the MNIST dataset.\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision\n",
    "\n",
    "# Load the MNIST training and test splits.\n",
    "ds_train = MNIST(root='./data', download=True, train=True)\n",
    "ds_test  = MNIST(root='./data', download=True, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f7fc9b-2a69-48eb-bea1-9cf97117ebf8",
   "metadata": {},
   "source": [
    "### Exercise 1.1: Exploratory data analysis\n",
    "\n",
    "Spend some time inspecting the `ds_train` and `ds_test` data structures in order to get a feel for the data. What is the format? How big are the images? How many are there? What about the range of pixel values? Where are the labels for images?\n",
    "\n",
    "Remember that one of the best ways to explore is to *visualize*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81157a27-3c60-432d-b3a0-6b6741f42747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f462b0-0bd1-4501-8b96-d34e8e873e8a",
   "metadata": {},
   "source": [
    "### Exercise 1.2: Dataset conversion and normalization\n",
    "\n",
    "+ **Datatype Conversion**:\n",
    "The first thing we need to do is convert all data tensors to `torch.float32` -- this is fundamental as it is extremely inconvenient to work with `uint8` data. Using 32-bit floating point numbers is a compromise between precision and space efficiency.\n",
    "The `torch.Tensor` class has a very useful method `to()` for performing datatype and device (e.g. to GPU) conversions. Check out the [documentation here](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html#torch-tensor-to).\n",
    "\n",
    "+ **Normalization**:\n",
    "Next, we need to correct the inconvenient range of [0, 255] for the pixel values. You should *subtract* the mean intensity value and divide by the standard deviation in order to *standardize* our data. **Important**: Think *very carefully* about *which* split you should use to compute the pixel statistics for standardization.\n",
    "\n",
    "+ **Reshaping**: Is the data in an appropriate format (i.e. shape) for the training the models we know? Think about whether (and how) to fix this if needed. \n",
    "\n",
    "**What to do**: In the cell below you should perform this sequence preprocessing operations on the `ds_train.data` and `ds_test.data` tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b71841-b3a6-4887-8c62-450aa4b36b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68fcf34-8efe-4224-8138-8739d6c2c23f",
   "metadata": {},
   "source": [
    "### Exercise 1.3: Subsampling the MNIST dataset.\n",
    "\n",
    "MNIST is kind of big, and thus inconvenient to work with unless using the GPU. For this laboratory we will use a smaller subset of the dataset for training to keep memory and computation times low.\n",
    "\n",
    "Modify `ds.train` to use only a subset of, say, 10000 images sampled from the original data. Make sure to select the correct corresponding targets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74d2ea58-1f86-42fe-b867-f824e4966ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d557069-7f6d-4765-938f-6ff3e360b15d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Establishing a stable baseline\n",
    "\n",
    "In this exercise you will establish a reliable baseline using a classical approach. This is an important step in our methodology in order to judge whether our Deep MLP is performing well or not.\n",
    "\n",
    "### Exercise 2.1: Establish the stable baseline\n",
    "\n",
    "Train and test your stable baseline to estimate the best achievable accuracy using classical models.\n",
    "\n",
    "**Tip**: Don't do any extensive cross-validation of your baseline (for now). Just fit a simple model (e.g. a linear SVM) and record the accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bf8cf7-0632-46fa-b97e-32eef1f166ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215ded91-0fc9-4923-883f-548adebbc4a1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Training some deep models (finally)\n",
    "\n",
    "Now we will finally train some deep models (Multilayer Perceptrons, to be precise). Since the dataset is a bit too large to use batch gradient descent, we will first need to set up a `torch.utils.data.DataLoader` for our training data. A `DataLoader` breaks the dataset up into a sequence of *batches* that will be used for training. In order to use this, we will first have to use `torch.utils.data.TensorDataset` on `ds_train.data` and `ds_train.targets` to make a new torch `dataset` for use in the dataloader. \n",
    "\n",
    "### Exercise 3.1: Creating the DataLoader\n",
    "\n",
    "Create a `DataLoader` for `ds_train` use a `batch_size` of about 16 or 32 to start. After you have your `DataLoader` experiment with is using `next(iter(dl_train))` to see what it returns. The pytorch `DataLoader` is a Python iterator.\n",
    "\n",
    "**EXTREMELY IMPORTANT**: Make sure you use `shuffle=True` in the constructor of your dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf280cd7-418f-4ed4-9ae8-4bb9a618e66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c40712-538f-4efa-9752-f58a866d357f",
   "metadata": {},
   "source": [
    "### Some support code (NOT an exercise).\n",
    "\n",
    "Here is some support code that you can use to train a model for a **single** epoch. The function returns the mean loss over all iterations. You will use it in the next exercise to train and monitor training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638ed76b-b385-46d2-904e-f2ee31b9a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model for a single epoch. You should pass it a model, a dataloader,\n",
    "# and an optimizer. Returns the mean loss over the entire epoch.\n",
    "def train_epoch(model, dl, optimizer):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for (xs, ys) in dl:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(xs)\n",
    "        loss = torch.nn.functional.nll_loss(output, ys)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    model.eval()\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaaaf4a-7266-43b8-a5b6-c36c7cb087bc",
   "metadata": {},
   "source": [
    "### Exercise 3.2: Defining a 1-layer neural network\n",
    "\n",
    "Define a simple model that uses a **single** `torch.nn.Linear` layer followed by a `torch.nn.Softmax` to predict  the output probabilities for the ten classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6f6ae8-5826-44ab-9077-6358f7585f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a fresh model.\n",
    "model = torch.nn.Sequential(\n",
    "    # Your code here.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0892210c-7b7c-4bab-a648-121d52190cb1",
   "metadata": {},
   "source": [
    "### Exercise 3.2: Training our model\n",
    "\n",
    "Instantiate a `torch.optim.SGD` optimizer using `model.parameters()` and the learning rate (**tip**: make the learning rate a variable you can easily change). Then run `train_epoch` for a set number of epochs (e.g. 100, make this a variable too). Is your model learning? How can you tell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca7a8f-f7a9-4536-a4ba-51ab0e9fbead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2209ce-48d6-4412-9973-456c2d0ae1f0",
   "metadata": {},
   "source": [
    "### Exercise 3.3: Evaluating our model\n",
    "\n",
    "Write some code to plot the loss curve for your training run and evaluate the performance of your model on the test data. Play with the hyperparameters (e.g. learning rate) to try to get the best performance on the test set. Can you beat the stable baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30c0f7a7-435d-490b-aa61-b240458776a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e688ba-cc3f-4445-ab6b-6675a446ba1c",
   "metadata": {},
   "source": [
    "### Exercise 3.4: A 2-layer MLP\n",
    "Now we will go (at least one layer) deeper to see if we can significantly improve on the baseline. Define a new model with one hidden layer. Use the code you wrote above to train and evaluate this new model. Can you beat the baseline? You might need to train in two stages using different learning rates.\n",
    "\n",
    "**Things to think about**:\n",
    "\n",
    "+ It might be hard to beat (or even equal) the baseline with deeper networks. Why?\n",
    "+ Is there something else we should be monitoring while training, especially for deep networks? How should we modify our dataset preparation and training loop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0c9686-49d7-4bc3-bbd9-0671547bd610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
